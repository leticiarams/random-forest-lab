{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only for format  the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "eps = np.finfo(float).eps\n",
    "from numpy import log2 as log\n",
    "from anytree import Node, RenderTree\n",
    "from anytree import search as anys\n",
    "from anytree.exporter import DotExporter\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and format dataset Titanic survived dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    549\n",
      "1    342\n",
      "Name: Survived, dtype: int64\n",
      "0    266\n",
      "1    152\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# laod original trainning dataset.\n",
    "train_data = pd.read_csv(\n",
    "    \"train.csv.titanic\",\n",
    "    sep=r'\\s*,\\s*',\n",
    "    quotechar=\"'\",\n",
    "    engine='python',\n",
    "    index_col=False,\n",
    "    na_values=\"?\")\n",
    "\n",
    "# Counting...\n",
    "Target = 'Survived'\n",
    "Labels = train_data[Target].unique()\n",
    "counts = train_data[Target].value_counts()\n",
    "print(counts)\n",
    "\n",
    "# laod original testing dataset (dataset without labels).\n",
    "test_data = pd.read_csv(\n",
    "    \"test.csv.titanic\",\n",
    "    sep=r'\\s*,\\s*',\n",
    "    engine='python',\n",
    "    quotechar=\"'\",\n",
    "    index_col=False,\n",
    "    na_values=\"?\")\n",
    "\n",
    "# Load labels for testing dataset.\n",
    "test_labels = pd.read_csv(\n",
    "    \"gender_submission.csv.titanic\",\n",
    "    sep=r'\\s*,\\s*',\n",
    "    engine='python',\n",
    "    na_values=\"?\")\n",
    "\n",
    "# Counting...\n",
    "Target = 'Survived'\n",
    "Labels = test_labels[Target].unique()\n",
    "counts = test_labels[Target].value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fusion labels to fusion train and test.\n",
    "test_data['Survived'] = test_labels['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusion the datasets using only selected features.\n",
    "final = pd.concat([train_data[[\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Embarked\",\"Survived\"]], test_data[[\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Embarked\",\"Survived\"]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling the data\n",
    "final = final.sample(frac=1)\n",
    "# Drop missing data\n",
    "final = final.dropna()\n",
    "# Convert to integer\n",
    "final['Age'] = final['Age'].astype('float').astype('int64')\n",
    "final['Fare'] = final['Fare'].astype('float').astype('int64')\n",
    "# Converto to categorical features\n",
    "final = final.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    628\n",
      "1    415\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# How much samples remaing.\n",
    "Target = 'Survived'\n",
    "Labels = final[Target].unique()\n",
    "counts = final[Target].value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data by labels.\n",
    "final0 = final.loc[final['Survived'] == 0]\n",
    "final1 = final.loc[final['Survived'] == 1]\n",
    "final0.reset_index(inplace=True)\n",
    "final1.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to use 'frac' parameter.\n",
    "# Split the data in frac < 1 for trainning and (1 - frac) for testing.\n",
    "\n",
    "def makedata(final0,final1,frac):\n",
    "    side0A = final0.loc[1:int(round(final0['index'].count()*frac)),:]\n",
    "    side0B = final0.loc[int(round(final0['index'].count()*frac)):,:]\n",
    "    side1A = final1.loc[1:int(round(final1['index'].count()*frac)),:]\n",
    "    side1B = final1.loc[int(round(final1['index'].count()*frac)):,:]\n",
    "    train = [side0A, side1A]\n",
    "    test = [side0B, side1B]\n",
    "    tempA = pd.concat(train).sample(frac=1)\n",
    "    tempA.reset_index(inplace=True)\n",
    "    tempB = pd.concat(test).sample(frac=1)\n",
    "    tempB.reset_index(inplace=True)\n",
    "    tempA = tempA.drop(tempA.columns[0:2], axis=1)\n",
    "    tempB = tempB.drop(tempB.columns[0:2], axis=1)\n",
    "    tempA = tempA.astype('str')\n",
    "    tempB = tempB.astype('str')\n",
    "    return tempA, tempB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = makedata(final0,final1,0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    377\n",
      "1    249\n",
      "Name: Survived, dtype: int64\n",
      "0    251\n",
      "1    166\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Counting...\n",
    "\n",
    "Target = 'Survived'\n",
    "Labels = train[Target].unique()\n",
    "counts = train[Target].value_counts()\n",
    "print(counts)\n",
    "\n",
    "Target = 'Survived'\n",
    "Labels = test[Target].unique()\n",
    "counts = test[Target].value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset in CSV.\n",
    "train.to_csv('dataset.training.csv.titanic', sep=',',  encoding='ascii', decimal='.', index=False, header=False)\n",
    "test.to_csv('dataset.test.csv.titanic', sep=',',  encoding='ascii', decimal='.', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entropy(df):\n",
    "    entropy = 0\n",
    "    values = df[Target].unique()\n",
    "    for value in values:\n",
    "        temp = df[Target].value_counts()[value]/len(df[Target])\n",
    "        entropy += -temp*np.log2(temp)\n",
    "    return entropy\n",
    "\n",
    "def find_entropy_attribute(df,attribute):\n",
    "    \n",
    "    if not np.issubdtype(df[attribute].dtype, np.number):   \n",
    "        return find_entropy_attribute_not_number(df,attribute), None\n",
    "    else:\n",
    "        return find_entropy_attribute_number(df,attribute)\n",
    "          \n",
    "        \n",
    "def find_entropy_attribute_not_number(df,attribute):\n",
    "    target_variables = df[Target].unique()  #This gives all 'Yes' and 'No'\n",
    "    variables = df[attribute].unique()    #This gives different features in that attribute (like 'Hot','Cold' in Temperature)\n",
    "    entropy2 = 0\n",
    "    for variable in variables:\n",
    "        entropy = 0\n",
    "        for target_variable in target_variables:\n",
    "            num = len(df[attribute][df[attribute]==variable][df[Target] ==target_variable])\n",
    "            den = len(df[attribute][df[attribute]==variable])\n",
    "            fraction = num/(den+eps)\n",
    "            entropy += -fraction*log(fraction+eps)\n",
    "        entropy2 += -(den/len(df))*entropy\n",
    "    return abs(entropy2)\n",
    "\n",
    "\n",
    "def find_entropy_attribute_number(df,attribute):\n",
    "    target_variables = df[Target].unique()  #This gives all 'Yes' and 'No'\n",
    "    variables = df[attribute].unique()    #This gives different features in that attribute (like 'Hot','Cold' in Temperature)\n",
    "    variables.sort()\n",
    "    if len(variables)>2:\n",
    "        variables = variables[1:-1]\n",
    "        vk3 = variables[0]\n",
    "        entropy3 = 0\n",
    "    else:\n",
    "        vk3 = variables[0]\n",
    "        entropy3 = np.Inf\n",
    "    \n",
    "    for vk in variables:\n",
    "        entropy = 0\n",
    "        for target_variable in target_variables:\n",
    "            num = len(df[attribute][df[attribute]<=vk][df[Target] ==target_variable])\n",
    "            den = len(df[attribute][df[attribute]<=vk])\n",
    "            fraction = num/(den+eps)\n",
    "            entropy += -fraction*log(fraction+eps)\n",
    "        for target_variable in target_variables:\n",
    "            num = len(df[attribute][df[attribute]>vk][df[Target] ==target_variable])\n",
    "            den = len(df[attribute][df[attribute]>vk])\n",
    "            fraction = num/(den+eps)\n",
    "            entropy += -fraction*log(fraction+eps)\n",
    "        entropy2 = (den/len(df))*abs(entropy)\n",
    "        #print(str(entropy2)+\"|\"+str(vk))\n",
    "        if entropy2>entropy3:\n",
    "            entropy3 = entropy2\n",
    "            vk3 = vk\n",
    "    return abs(entropy3),vk3\n",
    "\n",
    "def find_winner(df):\n",
    "    IG = []\n",
    "    vk = list()\n",
    "    for key in df.columns.difference([Target]):\n",
    "        temp,temp2 = find_entropy_attribute(df,key)\n",
    "        vk.append(temp2)\n",
    "        IG.append(find_entropy(df)-temp)\n",
    "    return df.columns.difference([Target])[np.argmax(IG)], vk[np.argmax(IG)]\n",
    "\n",
    "def buildtree(df,tree=None, mytree=None, T_pro=0.1, T_pro_num=0.4):\n",
    "    \n",
    "    def ramificatree(Thd):\n",
    "        if (len(clValue)==1):\n",
    "            tree[node][value] = clValue[0]\n",
    "            print(node +' : '+value+' : '+clValue[0])\n",
    "        else:\n",
    "            rel_counts = counts.min() / counts.max()\n",
    "            if (rel_counts<Thd):\n",
    "                tree[node][value] = clValue[counts.argmax()]\n",
    "                print(node +' : '+value+' : '+clValue[counts.argmax()])\n",
    "            else:\n",
    "                tree[node][value] = buildtree(subtable)\n",
    "                print(node +' : '+value+' : *')\n",
    "\n",
    "    #print(find_winner(df))\n",
    "    #formata_dados(dados)\n",
    "    node,vk = find_winner(df)\n",
    "\n",
    "    if tree is None:\n",
    "        tree={}\n",
    "        tree[node] = {}\n",
    "\n",
    "    if vk is None:\n",
    "        attValue = np.unique(df[node])\n",
    "        for value in attValue:\n",
    "\n",
    "            subtable = df[df[node] == value].reset_index(drop=True)\n",
    "            clValue,counts = np.unique(subtable[Target],return_counts=True)\n",
    "\n",
    "            ramificatree(T_pro)\n",
    "    else:\n",
    "        \n",
    "        if (len(df[node][df[node] <= vk].unique())>0) and (len(df[node][df[node] > vk].unique())>0):\n",
    "           \n",
    "            # >vk\n",
    "            value = node+' >'+str(vk)\n",
    "            subtable = df[df[node] > vk].rename(columns = {node:value}).reset_index(drop=True)\n",
    "            clValue,counts = np.unique(subtable[Target],return_counts=True)            \n",
    "            if (len(subtable[value].unique())==1) and (len(clValue)>1):\n",
    "                clValue = clValue[counts.argmax()]\n",
    "                tree[node][value] = clValue[0]\n",
    "                print(node +' : '+value+' : '+clValue[0])\n",
    "            else:\n",
    "                ramificatree(T_pro_num)\n",
    "            clValue_antes = clValue[0]\n",
    "            value_antes = value\n",
    "            # <=vk\n",
    "            value = node+' <='+str(vk)\n",
    "            subtable = df[df[node] <= vk].rename(columns = {node:value}).reset_index(drop=True)\n",
    "            clValue,counts = np.unique(subtable[Target],return_counts=True)\n",
    "            if ((len(subtable[value].unique())==1) and (len(clValue)>1)):\n",
    "                tree[node][value] = clValue[counts.argmax()]\n",
    "                print(node +' : '+value+' : '+clValue[counts.argmax()])\n",
    "            else:\n",
    "                ramificatree(T_pro_num)\n",
    "\n",
    "        else:\n",
    "            df[node] = df[node].astype(str)\n",
    "            buildtree(df)\n",
    "        \n",
    "    return tree\n",
    "\n",
    "\n",
    "# Only to see\n",
    "\n",
    "def print_tree(arg):\n",
    "    for pre, fill, node in RenderTree(arg):\n",
    "        print(\"%s%s\" % (pre, node.name))\n",
    "        \n",
    "def converte_para_anytree(tree,node=None,mytree=None):\n",
    "    \n",
    "    if node is None:\n",
    "        temp = list(tree.keys())\n",
    "        node = temp[0]\n",
    "        mytree = {}\n",
    "        mytree[node] = Node(node)\n",
    "        converte_para_anytree(tree,node,mytree)\n",
    "    else:\n",
    "        tree = tree[node]\n",
    "        if not isinstance(tree, str):\n",
    "            childs = list(tree.keys())\n",
    "            for child in childs:\n",
    "                if ((tree[child] == Labels[0]) or (tree[child] == Labels[1])):\n",
    "                    temp = mytree[node]\n",
    "                    mytree[child] = Node(child, parent=temp, target=tree[child])\n",
    "                else:\n",
    "                    temp = mytree[node]\n",
    "                    mytree[child] = Node(child, parent=temp)\n",
    "                    converte_para_anytree(tree,child,mytree)\n",
    "        else:\n",
    "            mytree[node] = 'Fim'\n",
    "                \n",
    "    return mytree\n",
    "\n",
    "#anys.findall_by_attr(mytree['Taste'], name=\"target\", value='Yes')\n",
    "\n",
    "def mostra_tree(tree):\n",
    "    mytree = converte_para_anytree(tree)\n",
    "\n",
    "    temp = list(tree.keys())\n",
    "    root = temp[0]\n",
    "    mytree[root]\n",
    "\n",
    "    for pre, fill, node in RenderTree(mytree[root]):\n",
    "        txt_node = str(node)\n",
    "        if  Labels[0] in txt_node:\n",
    "            print(\"%s%s\" % (pre, node.name+': '+Labels[0]))\n",
    "        elif Labels[1] in txt_node:\n",
    "            print(\"%s%s\" % (pre, node.name+': '+Labels[1]))\n",
    "        else:\n",
    "            print(\"%s%s\" % (pre, node.name))\n",
    "    \n",
    "    \n",
    "def mostra_tree_graph(tree, largura=None, altura=None):\n",
    "    mytree = converte_para_anytree(tree)\n",
    "\n",
    "    temp = list(tree.keys())\n",
    "    root = temp[0]\n",
    "    mytree[root]\n",
    "    DotExporter(mytree[root]).to_picture(\"tree.png\")\n",
    "    return Image(filename='tree.png', width=largura, height=altura) \n",
    "\n",
    "\n",
    "def predict(inst,tree):\n",
    "\n",
    "    for node in tree.keys():     \n",
    "\n",
    "        if ('<=' in str(tree[node].keys())):\n",
    "\n",
    "            childs = list(tree[node].keys())\n",
    "\n",
    "            if ('<=' in childs[1]):\n",
    "                temp = childs[1]\n",
    "                childs[1] = childs[0]\n",
    "                childs[0] = temp\n",
    "\n",
    "            vk = float(childs[1].split('>')[1])\n",
    "            valor = float(str(inst[node]))\n",
    "            if (valor > vk):\n",
    "                tree = tree[node][childs[1]]\n",
    "                prediction = None\n",
    "                if type(tree) is dict:\n",
    "                    prediction = predict(inst, tree)\n",
    "                else:\n",
    "                    prediction = tree\n",
    "                    break;\n",
    "            else:\n",
    "                tree = tree[node][childs[0]]\n",
    "                prediction = None\n",
    "                if type(tree) is dict:\n",
    "                    prediction = predict(inst, tree)\n",
    "                else:\n",
    "                    prediction = tree\n",
    "                    break;\n",
    "            \n",
    "        else:\n",
    "            value = inst[node]\n",
    "            if value in tree[node].keys():\n",
    "                tree = tree[node][value]\n",
    "                prediction = None\n",
    "                if type(tree) is dict:\n",
    "                    prediction = predict(inst, tree)\n",
    "                else:\n",
    "                    prediction = tree\n",
    "                    break;\n",
    "            else:\n",
    "                prediction = 'Not exists node.'\n",
    "        \n",
    "    return prediction\n",
    "\n",
    "def test_step(arg,tree):\n",
    "    S = 0\n",
    "    for i in range(0,len(arg)):\n",
    "        S += (predict(arg.iloc[i],tree) == arg.iloc[i].Target)*1\n",
    "\n",
    "    print(S / len(arg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be str, not numpy.int64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-94458b4b3a36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuildtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT_pro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-6a4a4579a00f>\u001b[0m in \u001b[0;36mbuildtree\u001b[0;34m(df, tree, mytree, T_pro, T_pro_num)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mclValue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mramificatree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT_pro\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-6a4a4579a00f>\u001b[0m in \u001b[0;36mramificatree\u001b[0;34m(Thd)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclValue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m' : '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' : '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mclValue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mrel_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: must be str, not numpy.int64"
     ]
    }
   ],
   "source": [
    "tree = None\n",
    "tree = buildtree(train_data,T_pro = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
